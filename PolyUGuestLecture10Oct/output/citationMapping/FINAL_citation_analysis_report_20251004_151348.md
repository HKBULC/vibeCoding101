# Final Comprehensive Citation Analysis Report\n\n**Generated:** 2025-10-04 15:13:48\n**Method:** Comprehensive individual reference search with correct spaced number format\n**Coverage:** Complete analysis of all 156 references in bibliography\n\n## Executive Summary\n\n- **Total citation instances found:** 301\n- **References cited:** 91 out of 156 (58.3%)\n- **Uncited references:** 65 (41.7%)\n- **Average citations per cited reference:** 3.3\n\n## Citation Frequency Analysis\n\n### Most Frequently Cited References\n\n1. **Reference #68** (12 citations)\n   Liddy ED (2 00 1). Natural language processing\n\n2. **Reference #5** (8 citations)\n   Androutsopoulos I, Paliouras G, Karkaletsis V, Sakkis G, Spyropoulos CD, Stamatopoulos P (2 00 0)\n\n3. **Reference #54** (8 citations)\n   Hayes PJ (1 99 2) Intelligent high-volume text processing using shallow, domain-specific techniques. Text-\n\n4. **Reference #77** (8 citations)\n   Mc Callum A, Nigam K (1 99 8) A comparison of event models for naive bayes text classification. In AAAI-\n\n5. **Reference #74** (7 citations)\n   Mani I, Maybury MT (eds) (1 99 9) Advances in automatic text summarization, vol 2 93. MIT press,\n\n6. **Reference #43** (6 citations)\n   Fattah MA, Ren F (2 00 9) GA, MR, FFNN, PNN and GMM based models for automatic text summari-\n\n7. **Reference #70** (6 citations)\n   Luong MT, Sutskever I, Le Q V, Vinyals O, Zaremba W (2 01 4) Addressing the rare word problem in\n\n8. **Reference #33** (5 citations)\n   Devlin J, Chang MW, Lee K, Toutanova K, (2 01 8) Bert: pre-training of deep bidirectional transformers for\n\n9. **Reference #35** (5 citations)\n   Doddington G (2 00 2) Automatic evaluation of machine translation quality using n-gram co-occurrence\n\n10. **Reference #63** (5 citations)\n   Kang Y, Cai Z, Tan CW, Huang Q, Liu H (2 02 0) Natural language processing (NLP) in management\n\n11. **Reference #1** (4 citations)\n   Ahonen H, Heinonen O, Klemettinen M, Verkamo AI (1 99 8) Applying data mining techniques for\n\n12. **Reference #2** (4 citations)\n   Alshawi H (1 99 2) The core language engine. MIT press\n\n13. **Reference #3** (4 citations)\n   Alshemali B, Kalita J (2 02 0) Improving the reliability of deep neural networks in NLP: A review. Knowl-\n\n14. **Reference #4** (4 citations)\n   Andreev ND (1 96 7) The intermediary language as the focal point of machine translation. In: Booth AD\n\n15. **Reference #6** (4 citations)\n   Baclic O, Tunis M, Young K, Doan C, Swerdfeger H, Schonfeld J (2 02 0) Artificial intelligence in public\n\n16. **Reference #8** (4 citations)\n   Bangalore S, Rambow O, Whittaker S (2 00 0) Evaluation metrics for generation. In proceedings of the first\n\n17. **Reference #13** (4 citations)\n   Benson E, Haghighi A, Barzilay R (2 01 1) Event discovery in social media feeds. In proceedings of the\n\n18. **Reference #14** (4 citations)\n   Berger AL, Della Pietra SA, Della Pietra VJ (1 99 6) A maximum entropy approach to natural language\n\n19. **Reference #16** (4 citations)\n   Bondale N, Maloor P, Vaidyanathan A, Sengupta S, Rao PV (1 99 9) Extraction of information from open-\n\n20. **Reference #18** (4 citations)\n   Briscoe EJ, Grover C, Boguraev B, Carroll J (1 98 7) A formalism and environment for the development of\n\n## Reference Coverage Analysis\n\n### Successfully Located Citations (91 references)\n\n- **Ref #1** (4x): Ahonen H, Heinonen O, Klemettinen M, Verkamo AI (1 99 8) Applying data mining techniques for...\n- **Ref #2** (4x): Alshawi H (1 99 2) The core language engine. MIT press...\n- **Ref #3** (4x): Alshemali B, Kalita J (2 02 0) Improving the reliability of deep neural networks in NLP: A review. K...\n- **Ref #4** (4x): Andreev ND (1 96 7) The intermediary language as the focal point of machine translation. In: Booth A...\n- **Ref #5** (8x): Androutsopoulos I, Paliouras G, Karkaletsis V, Sakkis G, Spyropoulos CD, Stamatopoulos P (2 00 0)...\n- **Ref #6** (4x): Baclic O, Tunis M, Young K, Doan C, Swerdfeger H, Schonfeld J (2 02 0) Artificial intelligence in pu...\n- **Ref #7** (3x): Bahdanau D, Cho K, Bengio Y (2 01 5) Neural machine translation by jointly learning to align and...\n- **Ref #8** (4x): Bangalore S, Rambow O, Whittaker S (2 00 0) Evaluation metrics for generation. In proceedings of the...\n- **Ref #9** (1x): Baud RH, Rassinoux AM, Scherrer JR (1 99 1) Knowledge representation of discharge summaries. In...\n- **Ref #10** (1x): Baud RH, Rassinoux AM, Scherrer JR (1 99 2) Natural language processing and semantical representatio...\n\n... and 81 more cited references.\n\n### Uncited References (65 references)\n\nThese references appear in the bibliography but were not cited in the text:\n\n- **Ref #78:** Mc Cray AT (1 99 1) Natural language processing for intelligent information retrieval. In Engineerin...\n- **Ref #79:** Mc Cray AT (1 99 1) Extending a natural language parser with UMLS knowledge. In proceedings of the...\n- **Ref #80:** Mc Cray AT, Nelson SJ (1 99 5) The representation of meaning in the UMLS. Methods Inf Med 3 4(1 – 2)...\n- **Ref #82:** Mc Cray AT, Srinivasan S, Browne AC (1 99 4) Lexical methods for managing variation in biomedical...\n- **Ref #84:** Mc Gray AT, Sponsler JL, Brylawski B, Browne AC (1 98 7) The role of lexical knowledge in biomedical...\n- **Ref #100:** Palmer M, Gildea D, Kingsbury P (2 00 5) The proposition bank: an annotated corpus of semantic roles...\n- **Ref #101:** Papineni K, Roukos S, Ward T, Zhu WJ (2 00 2) BLEU: a method for automatic evaluation of machine...\n- **Ref #102:** Peng Y, Chi J (2 01 9) Unsupervised cross-media retrieval using domain adaptation with scene graph. ...\n- **Ref #103:** Porter MF (1 98 0) An algorithm for suffix stripping. Program 1 4(3):1 30 – 1 37...\n- **Ref #104:** Rae JW, Potapenko A, Jayakumar SM, Lillicrap TP, (2 01 9) Compressive transformers for long-range...\n- **Ref #105:** Ranjan P, Basu HVSSA (2 00 3) Part of speech tagging and local word grouping techniques for natural...\n- **Ref #106:** Rassinoux AM, Baud RH, Scherrer JR (1 99 2) Conceptual graphs model extension for knowledge...\n- **Ref #107:** Rassinoux AM, Michel PA, Juge C, Baud R, Scherrer JR (1 99 4) Natural language processing of medical...\n- **Ref #108:** Rassinoux AM, Juge C, Michel PA, Baud RH, Lemaitre D, Jean FC, Scherrer JR (1 99 5) Analysis of...\n- **Ref #109:** Rennie J (2 00 0) ifile: An application of machine learning to e-mail filtering. In Proc. KDD 2 00 0...\n- **Ref #110:** Riedhammer K, Favre B, Hakkani-Tür D (2 01 0) Long story short – global unsupervised models for...\n- **Ref #111:** Ritter A, Clark S, Etzioni O (2 01 1) Named entity recognition in tweets: an experimental study. In...\n- **Ref #112:** Rospocher M, van Erp M, Vossen P, Fokkens A, Aldabe I, Rigau G, Soroa A, Ploeger T, Bogaard T(2 01 6...\n- **Ref #113:** Sager N, Lyman M, Tick LJ, Borst F, Nhan NT, Revillard C, … Scherrer JR (1 98 9) Adapting a medical...\n- **Ref #114:** Sager N, Lyman M, Nhan NT, Tick LJ (1 99 5) Medical language processing: applications to patient dat...\n\n... and 45 more uncited references.\n\n## Methodology Notes\n\nThis analysis used comprehensive pattern matching to account for the paper's specific citation format:\n- Spaced number format: [6 6] instead of [66]\n- Multiple citation formats: single, comma-separated, ranges\n- Author-citation combinations\n- Context extraction for verification\n\n## Data Quality\n\n✅ **Complete bibliography coverage:** All 156 references analyzed\n✅ **Format-aware searching:** Handles spaced number citations\n✅ **Context preservation:** Each citation mapped to paragraph context\n✅ **Comprehensive patterns:** Multiple search patterns per reference\n